{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from os import path\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKS = json.loads(open('website/content/links.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_TO_UID = {}\n",
    "for link in LINKS:\n",
    "    URL_TO_UID[link['url_more']] = link['uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(page):\n",
    "    meta = page.find_all('meta', {\"name\" : \"description\"})\n",
    "    if len(meta) > 0:\n",
    "        return meta[0].attrs['content']\n",
    "    meta_og = page.find_all('meta', {\"property\" : \"og:description\"})\n",
    "    if len(meta_og) > 0:\n",
    "        return meta_og[0].attrs['content']\n",
    "    return ''\n",
    "\n",
    "def get_time(page):\n",
    "    meta = page.find_all('meta', {\"property\": \"article:published_time\"})\n",
    "    if len(meta) > 0:\n",
    "        time_str = meta[0].attrs['content']\n",
    "        try:\n",
    "            d = datetime.datetime.fromisoformat(time_str.replace('Z',''))\n",
    "        except:\n",
    "            d = datetime.datetime.now()\n",
    "    else:\n",
    "        d = datetime.datetime.now()\n",
    "    return d.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "def get_title(page):\n",
    "    title = page.title\n",
    "    if title:\n",
    "        return title.text\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:8081/on-my-website-2018'\n",
    "soup = BeautifulSoup(requests.get(url).content)\n",
    "links = soup.find_all('a')[1:]\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not connect to  https://pentandra.com/blog/putting-the-pieces-together-technology/\n",
      "Could not connect to  https://pentandra.com/blog/putting-the-pieces-together-technology/\n",
      "http://jupyterhub.readthedocs.io/en/latest/ JupyterHub JupyterHub — JupyterHub 1.0.1dev documentation\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier jupyterhub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  http://jupyterhub.readthedocs.io/en/latest/\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'jupyterhub', 'date': '2019-11-14T15:12:04Z', 'title': 'JupyterHub — JupyterHub 1.0.1dev documentation', 'description': '', 'thumbnail': '/thumbnail/jupyterhub.png', 'url_more': 'http://jupyterhub.readthedocs.io/en/latest/'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://research.google.com/colaboratory will even be \"free\" \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier colaboratory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://research.google.com/colaboratory\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'colaboratory', 'date': '2019-11-14T15:12:11Z', 'title': '', 'description': '', 'thumbnail': '/thumbnail/colaboratory.png', 'url_more': 'https://research.google.com/colaboratory'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://em.geosci.xyz/content/maxwell2_static/fields_from_grounded_sources_dcr/electrostatic_sphere.html figures Conducting sphere in a uniform electric field — Electromagnetic Geophysics\n",
      "An open source textbook on applied electromagnetic geophysics. Aimed at providing background and physical understanding for steady state Maxwell equations as they apply to geoscience problems.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier geosci-electrostatic-sphere\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://em.geosci.xyz/content/maxwell2_static/fields_from_grounded_sources_dcr/electrostatic_sphere.html\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'geosci-electrostatic-sphere', 'date': '2019-11-14T15:12:28Z', 'title': 'Conducting sphere in a uniform electric field — Electromagnetic Geophysics', 'description': 'An open source textbook on applied electromagnetic geophysics. Aimed at providing background and physical understanding for steady state Maxwell equations as they apply to geoscience problems.', 'thumbnail': '/thumbnail/geosci-electrostatic-sphere.png', 'url_more': 'https://em.geosci.xyz/content/maxwell2_static/fields_from_grounded_sources_dcr/electrostatic_sphere.html'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://blog.getpelican.com/ static site generator Pelican Static Site Generator, Powered by Python\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier python-pelican\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://blog.getpelican.com/\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'python-pelican', 'date': '2019-11-14T15:12:45Z', 'title': 'Pelican Static Site Generator, Powered by Python', 'description': '', 'thumbnail': '/thumbnail/python-pelican.png', 'url_more': 'https://blog.getpelican.com/'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://pages.github.com/ GitHub Pages GitHub Pages | Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.\n",
      "Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier github-pages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://pages.github.com/\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'github-pages', 'date': '2019-11-14T15:12:57Z', 'title': 'GitHub Pages | Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.', 'description': 'Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.', 'thumbnail': '/thumbnail/github-pages.png', 'url_more': 'https://pages.github.com/'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://vimeo.com/232230096 Chalk Talk Ken Perlin:​ Chalktalk in Augmented Reality​ on Vimeo\n",
      "Chalktalk is now open source - http://frl.nyu.edu/chalktalk-is-now-open-source/\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier chalk-talk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://vimeo.com/232230096\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'chalk-talk', 'date': '2019-11-14T15:13:09Z', 'title': 'Ken Perlin:\\u200b Chalktalk in Augmented Reality\\u200b on Vimeo', 'description': 'Chalktalk is now open source - http://frl.nyu.edu/chalktalk-is-now-open-source/', 'thumbnail': '/thumbnail/chalk-talk.png', 'url_more': 'https://vimeo.com/232230096'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://mrl.nyu.edu/~perlin/ Ken Perlin Ken Perlin's homepage\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier ken-perlin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  http://mrl.nyu.edu/~perlin/\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'ken-perlin', 'date': '2019-11-14T15:13:20Z', 'title': \"Ken Perlin's homepage\", 'description': '', 'thumbnail': '/thumbnail/ken-perlin.png', 'url_more': 'http://mrl.nyu.edu/~perlin/'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "http://schema.org/CreativeWork rigorously defining CreativeWork - schema.org Type\n",
      "Schema.org Type: CreativeWork - The most generic kind of creative work, including books, movies, photographs, software programs, etc.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier schema-creative-work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  http://schema.org/CreativeWork\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'schema-creative-work', 'date': '2019-11-14T15:13:35Z', 'title': 'CreativeWork - schema.org Type', 'description': 'Schema.org Type: CreativeWork - The most generic kind of creative work, including books, movies, photographs, software programs, etc.', 'thumbnail': '/thumbnail/schema-creative-work.png', 'url_more': 'http://schema.org/CreativeWork'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Link already exists, skipping\n",
      "https://www.force11.org/community/members-directory commoners Community Members | FORCE11\n",
      "FORCE11 is a community of scholars, librarians, archivists, publishers and research funders that has arisen organically to help facilitate the change toward improved knowledge creation and sharing. Individually and collectively, we aim to bring about a change in modern scholarly communications through the effective use of information technology.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier force11-members\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://www.force11.org/community/members-directory\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'force11-members', 'date': '2019-11-14T15:13:54Z', 'title': 'Community Members | FORCE11', 'description': 'FORCE11 is a community of scholars, librarians, archivists, publishers and research funders that has arisen organically to help facilitate the change toward improved knowledge creation and sharing. Individually and collectively, we aim to bring about a change in modern scholarly communications through the effective use of information technology.', 'thumbnail': '/thumbnail/force11-members.png', 'url_more': 'https://www.force11.org/community/members-directory'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://dynamicland.org/ Chapter 4 Dynamicland\n",
      "incubating a humane dynamic medium\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier dynamicland\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://dynamicland.org/\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'dynamicland', 'date': '2019-11-14T15:14:06Z', 'title': 'Dynamicland', 'description': 'incubating a humane dynamic medium', 'thumbnail': '/thumbnail/dynamicland.png', 'url_more': 'https://dynamicland.org/'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://www.mendeley.com/guides/web/04-complete-profile communicate who you are and what you've done as a researcher 03. Complete your profile | Mendeley\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier mendeley-profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://www.mendeley.com/guides/web/04-complete-profile\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'mendeley-profile', 'date': '2019-11-14T15:14:19Z', 'title': '03. Complete your profile | Mendeley', 'description': '', 'thumbnail': '/thumbnail/mendeley-profile.png', 'url_more': 'https://www.mendeley.com/guides/web/04-complete-profile'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "https://lindseyjh.ca/ Lindsey Heagy Lindsey J Heagy\n",
      "Lindsey Heagy's personal website.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier lindsey-heagy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://lindseyjh.ca/\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'lindsey-heagy', 'date': '2019-11-14T15:14:34Z', 'title': 'Lindsey J Heagy', 'description': \"Lindsey Heagy's personal website.\", 'thumbnail': '/thumbnail/lindsey-heagy.png', 'url_more': 'https://lindseyjh.ca/'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Could not connect to  https://pentandra.com\n",
      "https://twitter.com/EvanBianco Evan Bianco Evan Bianco (@EvanBianco) | Twitter\n",
      "The latest Tweets from Evan Bianco (@EvanBianco). Agile* | Earth | Subsurface | Geoscience | Machine Learning |. Nova Scotia, Canada\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Unique identifier evan-bianco\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://twitter.com/EvanBianco\n",
      "Thumbnail created.\n",
      "{'__class__': 'Link', 'uid': 'evan-bianco', 'date': '2019-11-14T15:14:51Z', 'title': 'Evan Bianco (@EvanBianco) | Twitter', 'description': 'The latest Tweets from Evan Bianco (@EvanBianco). Agile* | Earth | Subsurface | Geoscience | Machine Learning |. Nova Scotia, Canada', 'thumbnail': '/thumbnail/evan-bianco.png', 'url_more': 'https://twitter.com/EvanBianco'}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for link in links:\n",
    "    url = link.attrs['href']\n",
    "    text = link.text\n",
    "    if not (url.startswith('//') or url.startswith('http')):\n",
    "        print('Link is internal, skipping')\n",
    "        continue\n",
    "    if url in URL_TO_UID:\n",
    "        print('Link already exists, skipping')\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        resp = requests.get(url, timeout=5)\n",
    "    except:\n",
    "        print('Could not connect to ', url)\n",
    "        continue\n",
    "        \n",
    "    page = BeautifulSoup(resp.content)\n",
    "    print(url, text, get_title(page))\n",
    "    print(get_description(page))\n",
    "    uid = input(\"Unique identifier\")\n",
    "    if uid == 'q':\n",
    "        break\n",
    "    \n",
    "    if not path.exists('website/static/thumbnail/' + uid + '.png'):\n",
    "        ! node screenshot.js --url \"$url\" --id $uid --path website/static/thumbnail\n",
    "    else:\n",
    "        print('Screenshot already exists, skipping')\n",
    "    \n",
    "    link_json = {\n",
    "        '__class__': 'Link',\n",
    "        'uid': uid,\n",
    "        'date': get_time(page),\n",
    "        'title': get_title(page),\n",
    "        'description': get_description(page),\n",
    "        'thumbnail': f'/thumbnail/{uid}.png',\n",
    "        'url_more': url\n",
    "    }\n",
    "    \n",
    "    print(link_json)\n",
    "    \n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "    LINKS += [link_json]\n",
    "    URL_TO_UID[url] = uid\n",
    "    \n",
    "# Dump the links out\n",
    "with open('website/content/links.json', 'w') as out:\n",
    "    json.dump(LINKS, out, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dump the links out\n",
    "with open('website/content/links.json', 'w') as out:\n",
    "    json.dump(LINKS, out, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot created of  https://scholar.google.ca/citations?user=k8DpDMMAAAAJ&hl=en\n",
      "Thumbnail created.\n"
     ]
    }
   ],
   "source": [
    "! node screenshot.js --url \"$url\" --id $uid --path website/static/thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "hello asdf\n",
      "hello asdf\n"
     ]
    }
   ],
   "source": [
    "for x in range(2):\n",
    "    input('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ _: [],\n",
      "  url: 'https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science',\n",
      "  id: 'guardian-publishing',\n",
      "  path: 'website/static/thumbnail',\n",
      "  '$0': 'screenshot.js' }\n",
      "Screenshot created of  https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science\n",
      "Thumbnail created.\n"
     ]
    }
   ],
   "source": [
    "! node screenshot.js --url $url --id $uid --path website/static/thumbnail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewrite the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_links(line):\n",
    "    soup = BeautifulSoup(line)\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    ws_line = len(line) - len(line.lstrip())\n",
    "\n",
    "    for link in links:\n",
    "\n",
    "        url = link.attrs['href']\n",
    "        if not (url.startswith('//') or url.startswith('http')):\n",
    "            uid = url.strip('/')\n",
    "        elif url in URL_TO_UID:\n",
    "            uid = URL_TO_UID[url]\n",
    "        else:\n",
    "            continue\n",
    "        link.name = 'ink-a'\n",
    "        if 'target' in link.attrs:\n",
    "            del link.attrs['target']\n",
    "        if 'href' in link.attrs:\n",
    "            del link.attrs['href']\n",
    "        link.attrs['src'] = '/' + uid\n",
    "        \n",
    "    if line.lstrip()[0] == '<':\n",
    "        out = ' '*ws_line + str(soup).replace('<html><body>','').replace('</body></html>','')\n",
    "    else:\n",
    "        out = ' '*ws_line + str(soup).replace('<html><body><p>','').replace('</p></body></html>','')\n",
    "    \n",
    "    # print(line)\n",
    "    # print(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = []\n",
    "for line in open('website/content/on-my-website-2018/content.html'):\n",
    "\n",
    "    if '<a' in line:\n",
    "        line = process_links(line)\n",
    "    fout += [line]\n",
    "\n",
    "f = open('website/content/on-my-website-2018/content.html', 'w')\n",
    "\n",
    "for line in fout:\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
